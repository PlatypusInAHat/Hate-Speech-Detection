model:
  name: "vinai/phobert-base"
  num_labels: 3
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  max_position_embeddings: 256

data:
  train_path: "data/train.csv"
  test_path: "data/test.csv"
  max_length: 256

training:
  batch_size: 32  # Increased batch size
  epochs: 15  # Increased epochs
  learning_rate: 3e-5  # Fine-tuned LR
  warmup_steps: 500
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  logging_steps: 50
  save_total_limit: 3
  seed: 42
  fp16: true  # Use mixed precision training
  optim: "adamw_torch"
  early_stopping_patience: 4
  early_stopping_threshold: 0.0001

evaluation:
  batch_size: 32
  metrics: ["accuracy", "precision", "recall", "f1"]
  metric_for_best_model: "f1"
  greater_is_better: true

paths:
  output_dir: "./results"
  model_save_path: "./saved_model"
  log_dir: "./logs"

wandb:
  project: "Vietnamese-Text-Classification"
  name: "PhoBERT-Training-Tuned"
  enabled: true
